# 使用 Kubectl 部署 NebulaGraph 集群

!!! Compatibility "历史版本兼容性"

    1.x 版本的 NebulaGraph Operator 不兼容 3.x 以下版本的 NebulaGraph。

## 前提条件

- [安装 NebulaGraph Operator](../2.deploy-nebula-operator.md)
- [已创建 StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/)

{{ ent.ent_begin }}
- 准备相应的 License 文件

  !!! enterpriseonly

        只有当创建的 NebulaGraph 集群是企业版本时，才需要提供 License 文件。
{{ ent.ent_end }}

## 创建集群

本文以创建名为`nebula`的集群为例，说明如何部署 NebulaGraph 集群。

1. 创建集群配置文件。
   
  - 社区版集群示例。
  
    创建名为`apps_v1alpha1_nebulacluster.yaml`的文件。文件内容参见[示例配置](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/config/samples/apps_v1alpha1_nebulacluster.yaml)。

    示例配置的参数描述如下：

    | 参数    | 默认值  | 描述    |
    | :---- | :--- | :--- |
    | `metadata.name`              | -                                                            | 创建的 NebulaGraph 集群名称。 |
    | `spec.graphd.replicas`       | `1`                                                          | Graphd 服务的副本数。         |
    | `spec.graphd.images`         | `vesoft/nebula-graphd`                                       | Graphd 服务的容器镜像。       |
    | `spec.graphd.version`        | `{{nebula.tag}}`                                                     | Graphd 服务的版本号。         |
    | `spec.graphd.service`        |                                                             | 访问 Graphd 服务的 Service 配置。      | 
    | `spec.graphd.logVolumeClaim.storageClassName`   | -                                                            | Graphd 服务的日志盘存储卷的存储类名称。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。        |
    | `spec.metad.replicas`        | `1`                                                          | Metad 服务的副本数。          |
    | `spec.metad.images`          | `vesoft/nebula-metad`                                        | Metad 服务的容器镜像。        |
    | `spec.metad.version`         | `{{nebula.tag}}`                                                     | Metad 服务的版本号。          |
    | `spec.metad.dataVolumeClaim.storageClassName`    | -                                                            | Metad 服务的数据盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。        |
    | `spec.metad.logVolumeClaim.storageClassName`|-|Metad 服务的日志盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。 |
    | `spec.storaged.replicas`     | `3`                                                          | Storaged 服务的副本数。       |
    | `spec.storaged.images`       | `vesoft/nebula-storaged`                                     | Storaged 服务的容器镜像。     |
    | `spec.storaged.version`      | `{{nebula.tag}}`                                                     | Storaged 服务的版本号。       |
    | `spec.storaged.dataVolumeClaims.resources.requests.storage` | -                                                            | Storaged 服务的数据盘存储大小，可指定多块数据盘存储数据。当指定多块数据盘时，路径为：`/usr/local/nebula/data1`、`/usr/local/nebula/data2`等。 |
    | `spec.storaged.dataVolumeClaims.resources.storageClassName` | -                                                            | Storaged 服务的数据盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。  |
    | `spec.storaged.logVolumeClaim.storageClassName`|-|Storaged 服务的日志盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。 |
    | `spec.reference.name`        | -                                                            | 依赖的控制器名称。           |
    | `spec.schedulerName`         | -                                                            | 调度器名称。                 |
    | `spec.imagePullPolicy`       | NebulaGraph 镜像的拉取策略。关于拉取策略详情，请参考 [Image pull policy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy)。 | 镜像拉取策略。               |
    |`spec.logRotate`| - |日志轮转配置。详情参见[管理集群日志](../8.custom-cluster-configurations/8.4.manage-running-logs.md)。|
    |`spec.enablePVReclaim`|`false`|定义是否在删除集群后自动删除 PVC 以释放数据。详情参见[回收 PV](../8.custom-cluster-configurations/8.2.pv-reclaim.md)。|


  {{ ent.ent_begin }}

  - 企业版集群示例。
  
    创建名为`apps_v1alpha1_nebulacluster.yaml`的文件。联系销售人员获取完整配置示例。


    企业版特有参数描述如下：

    | 参数    | 默认值  | 描述    |
    | :---- | :--- | :--- |
    | `spec.metad.license`       | - | 创建企业版 NebulaGraph 集群所需的 License 配置。               | 
    |`spec.storaged.enableAutoBalance`| `false`| 是否启用自动均衡。详情参见[均衡扩容后的 Storage 数据](../8.custom-cluster-configurations/8.3.balance-data-when-scaling-storage.md)。|
    |`spec.enableBR`|`false`|定义是否启用 BR 工具。详情参见[备份与恢复](../10.backup-restore-using-operator.md)。|

  !!! enterpriseonly

        拉取企业版 NebulaGraph 集群镜像前，请确保已联系销售人员（[inqury@vesoft.com](mailto:inqury@vesoft.com)）获取企业版 NebulaGraph 集群的镜像信息。


2. 配置集群 License。

  !!! enterpriseonly

      - 此步骤只适用于创建企业版 NebulaGraph集群。
  
      - 创建社区版 NebulaGraph 集群时，忽略此步骤。

  ```bash
  kubectl create secret generic nebula-license --from-file=nebula.license
  ```

  查看集群 License 信息：

  ```bash
  kubectl get secrets nebula-license -o yaml
  ```

  {{ ent.ent_end }}


3. 创建 NebulaGraph 集群。

  ```bash
  kubectl create -f apps_v1alpha1_nebulacluster.yaml
  ```

  返回：

  ```bash
  nebulacluster.apps.nebula-graph.io/nebula created
  ```


4. 查看 NebulaGraph 集群状态。
   
  ```bash
  kubectl get nebulaclusters nebula
  ```

  返回：

  ```bash
  NAME     GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE
  nebula   1                1              1               1             3                  3                86s
  ```

## 扩缩容集群

- 不支持扩缩容社区版的 NebulaGraph 集群。

{{ ent.ent_begin }}

- 仅支持通过 v1.1.0 及以上版本的 NebulaGraph Operator 扩缩容企业版的 NebulaGraph 集群。
  
用户可以通过编辑`apps_v1alpha1_nebulacluster.yaml`文件中的`replicas`的值进行 NebulaGraph 集群的扩缩容。

### 扩容集群

本文举例扩容 NebulaGraph 集群中 Storage 服务至 5 个。步骤如下：

1. 将`apps_v1alpha1_nebulacluster.yaml`文件中`storaged.replicas`的参数值从`3`改为`5`。

  ```yaml
    storaged:
      resources:
        requests:
          cpu: "500m"
          memory: "500Mi"
        limits:
          cpu: "1"
          memory: "1Gi"
      replicas: 5
      image: vesoft/nebula-storaged
      version: {{nebula.tag}}
      dataVolumeClaims:
      - resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
      - resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
      logVolumeClaim:
        resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
    reference:
      name: statefulsets.apps
      version: v1
    schedulerName: default-scheduler
  ```

2. 执行以下命令使上述更新同步至 NebulaGraph 集群 CR 中。

  ```bash
  kubectl apply -f apps_v1alpha1_nebulacluster.yaml
  ```
  
3. 查看 Storage 服务的副本数。

  ```bash
  kubectl  get pods -l app.kubernetes.io/cluster=nebula
  ```
  返回：

  ```bash
  NAME                READY   STATUS    RESTARTS   AGE
  nebula-graphd-0     1/1     Running   0          2m
  nebula-metad-0      1/1     Running   0          2m
  nebula-storaged-0   1/1     Running   0          2m
  nebula-storaged-1   1/1     Running   0          2m
  nebula-storaged-2   1/1     Running   0          2m
  nebula-storaged-3   1/1     Running   0          5m
  nebula-storaged-4   1/1     Running   0          5m
  ```
  由上可看出 Storage 服务的副本数被扩容至 5 个。

### 缩容集群

缩容集群的原理和扩容一样，用户只需将`apps_v1alpha1_nebulacluster.yaml`文件中的`replicas`的值缩小。具体操作，请参考上文的**扩容集群**部分。

!!! caution

    目前仅支持对 NebulaGraph 集群中的 Graph 服务和 Storage 服务进行扩缩容，不支持扩缩容 Meta 服务。

{{ ent.ent_end }}

## 删除集群

使用 Kubectl 删除 NebulaGraph 集群的命令如下：

```bash
kubectl delete -f apps_v1alpha1_nebulacluster.yaml
```

## 后续操作

[连接 NebulaGraph 数据库](../4.connect-to-nebula-graph-service.md)


