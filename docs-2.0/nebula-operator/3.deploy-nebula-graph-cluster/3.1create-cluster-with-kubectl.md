# 使用 Kubectl 部署{{nebula.name}}集群

!!! Compatibility "历史版本兼容性"

    1.x 版本的 NebulaGraph Operator 不兼容 3.x 以下版本的{{nebula.name}}。

## 前提条件

- [安装 NebulaGraph Operator](../2.deploy-nebula-operator.md)
- [已创建 StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/)
{{ent.ent_begin}}
- [已安装 LM 并加载 License Key](3.0.deploy-lm.md)
{{ent.ent_end}}

## 创建集群

本文以创建名为`nebula`的集群为例，说明如何部署{{nebula.name}}集群。

1. 创建命名空间，例如`nebula`。如果不指定命名空间，默认使用`default`命名空间。

  ```bash
  kubectl create namespace nebula
  ```

  {{ent.ent_begin}}
2. 创建 Secret，用于拉取私有仓库中{{nebula.name}}镜像。

  ```bash
  kubectl -n <nebula> create secret docker-registry <image-pull-secret> \
  --docker-server=DOCKER_REGISTRY_SERVER \
  --docker-username=DOCKER_USER \
  --docker-password=DOCKER_PASSWORD
  ```

  - `<nebula>`：存放该 Secret 的命名空间。
  - `<image-pull-secret>`：指定 Secret 的名称。
  - DOCKER_REGISTRY_SERVE：指定拉取镜像的私有仓库服务器地址，例如`reg.example-inc.com`。
  - DOCKER_USE：镜像仓库用户名。
  - DOCKER_PASSWORD：镜像仓库密码。
  {{ent.ent_end}}

3. 创建集群配置文件。
   
  {{comm.comm_begin}}
  创建名为`apps_v1alpha1_nebulacluster.yaml`的文件。文件内容参见[示例配置](https://github.com/vesoft-inc/nebula-operator/blob/v{{operator.release}}/config/samples/apps_v1alpha1_nebulacluster.yaml)。
  {{comm.comm_end}}

  {{ent.ent_begin}}
  联系销售人员获取完整配置示例。必须自定义修改以下参数，其他参数可按需修改。

    - `spec.metad.licenseManagerURL`
    - `spec.<graphd|metad|storaged>.image`
    - `spec.imagePullSecrets`
  {{ent.ent_end}}

  示例配置的参数描述如下：

  | 参数    | 默认值  | 描述    |
  | :---- | :--- | :--- |
  | `metadata.name`              | -                                                            | 创建的{{nebula.name}}集群名称。 |
  | `spec.graphd.replicas`       | `1`                                                          | Graphd 服务的副本数。         |
  | `spec.graphd.image`         | `vesoft/nebula-graphd`                                       | Graphd 服务的容器镜像。       |
  | `spec.graphd.version`        | `{{nebula.tag}}`                                                     | Graphd 服务的版本号。         |
  | `spec.graphd.service`        |                                                             | 访问 Graphd 服务的 Service 配置。      | 
  | `spec.graphd.logVolumeClaim.storageClassName`   | -                                                            | Graphd 服务的日志盘存储卷的存储类名称。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。        |
  | `spec.metad.replicas`        | `1`                                                          | Metad 服务的副本数。          |
  | `spec.metad.image`          | `vesoft/nebula-metad`                                        | Metad 服务的容器镜像。        |
  | `spec.metad.version`         | `{{nebula.tag}}`                                                     | Metad 服务的版本号。          |
  | `spec.metad.dataVolumeClaim.storageClassName`    | -                                                            | Metad 服务的数据盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。        |
  | `spec.metad.logVolumeClaim.storageClassName`|-|Metad 服务的日志盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。 |
  | `spec.storaged.replicas`     | `3`                                                          | Storaged 服务的副本数。       |
  | `spec.storaged.image`       | `vesoft/nebula-storaged`                                     | Storaged 服务的容器镜像。     |
  | `spec.storaged.version`      | `{{nebula.tag}}`                                                     | Storaged 服务的版本号。       |
  | `spec.storaged.dataVolumeClaims.resources.requests.storage` | -                                                            | Storaged 服务的数据盘存储大小，可指定多块数据盘存储数据。当指定多块数据盘时，路径为：`/usr/local/nebula/data1`、`/usr/local/nebula/data2`等。 |
  | `spec.storaged.dataVolumeClaims.resources.storageClassName` | -                                                            | Storaged 服务的数据盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。  |
  | `spec.storaged.logVolumeClaim.storageClassName`|-|Storaged 服务的日志盘存储配置。使用示例配置时需要将其替换为事先创建的存储类名称，参见 [Storage Classes](https://kubernetes.io/docs/concepts/storage/storage-classes/) 查看创建存储类详情。 |
  |`spec.agent`|`{}`| Agent 服务的配置。用于备份和恢复及日志清理功能，如果不自定义该配置，将使用默认配置。|
  | `spec.reference.name`        | -                                                            | 依赖的控制器名称。           |
  | `spec.schedulerName`         | -                                                            | 调度器名称。                 |
  | `spec.imagePullPolicy`       | {{nebula.name}}镜像的拉取策略。关于拉取策略详情，请参考 [Image pull policy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy)。 | 镜像拉取策略。               |
  |`spec.logRotate`| - |日志轮转配置。详情参见[管理集群日志](../8.custom-cluster-configurations/8.4.manage-running-logs.md)。|
  |`spec.enablePVReclaim`|`false`|定义是否在删除集群后自动删除 PVC 以释放数据。详情参见[回收 PV](../8.custom-cluster-configurations/8.2.pv-reclaim.md)。|
  
  {{ ent.ent_begin }}

  {{nebula.name}}特有参数描述如下：

  | 参数    | 默认值  | 描述    |
  | :---- | :--- | :--- |
  | `spec.metad.licenseManagerURL`       | - | 配置指向 [LM](../../9.about-license/2.license-management-suite/3.license-manager.md) 的 URL，由 LM 的访问地址和端口（默认端口`9119`）组成。例如，`192.168.8.100:9119`。**必须配置此参数以获取 License 信息，否则无法使用{{nebula.name}}集群。** |
  |`spec.storaged.enableAutoBalance`| `false`| 是否启用自动均衡。详情参见[均衡扩容后的 Storage 数据](../8.custom-cluster-configurations/8.3.balance-data-when-scaling-storage.md)。|
  |`spec.enableBR`|`false`|定义是否启用 BR 工具。详情参见[备份与恢复](../10.backup-restore-using-operator.md)。|
  |`spec.imagePullSecrets`| - |定义拉取私有仓库中镜像所需的 Secret。|

  !!! enterpriseonly

        拉取{{nebula.name}}集群镜像前，请确保已联系销售人员（[inqury@vesoft.com](mailto:inqury@vesoft.com)）获取{{nebula.name}}集群的镜像信息。

  {{ ent.ent_end }}

4. 创建{{nebula.name}}集群。

  ```bash
  kubectl create -f apps_v1alpha1_nebulacluster.yaml
  ```

  返回：

  ```bash
  nebulacluster.apps.nebula-graph.io/nebula created
  ```


5. 查看{{nebula.name}}集群状态。
   
  ```bash
  kubectl get nebulaclusters nebula
  ```

  返回：

  ```bash
  NAME     GRAPHD-DESIRED   GRAPHD-READY   METAD-DESIRED   METAD-READY   STORAGED-DESIRED   STORAGED-READY   AGE
  nebula   1                1              1               1             3                  3                86s
  ```

## 扩缩容集群

{{comm.comm_begin}}
不支持扩缩容社区版的{{nebula.name}}集群。
{{comm.comm_end}}

{{ ent.ent_begin }}

仅支持通过 v1.1.0 及以上版本的 NebulaGraph Operator 扩缩容{{nebula.name}}集群。
  
用户可以通过编辑`apps_v1alpha1_nebulacluster.yaml`文件中的`replicas`的值进行{{nebula.name}}集群的扩缩容。

### 扩容集群

本文举例扩容{{nebula.name}}集群中 Storage 服务至 5 个。步骤如下：

1. 将`apps_v1alpha1_nebulacluster.yaml`文件中`storaged.replicas`的参数值从`3`改为`5`。

  ```yaml
    storaged:
      resources:
        requests:
          cpu: "500m"
          memory: "500Mi"
        limits:
          cpu: "1"
          memory: "1Gi"
      replicas: 5
      image: vesoft/nebula-storaged
      version: {{nebula.tag}}
      dataVolumeClaims:
      - resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
      - resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
      logVolumeClaim:
        resources:
          requests:
            storage: 2Gi
        storageClassName: fast-disks
    reference:
      name: statefulsets.apps
      version: v1
    schedulerName: default-scheduler
  ```

2. 执行以下命令使上述更新同步至{{nebula.name}}集群 CR 中。

  ```bash
  kubectl apply -f apps_v1alpha1_nebulacluster.yaml
  ```
  
3. 查看 Storage 服务的副本数。

  ```bash
  kubectl get pods -l app.kubernetes.io/cluster=nebula
  ```
  返回：

  ```bash
  NAME                READY   STATUS    RESTARTS   AGE
  nebula-graphd-0     1/1     Running   0          2m
  nebula-metad-0      1/1     Running   0          2m
  nebula-storaged-0   1/1     Running   0          2m
  nebula-storaged-1   1/1     Running   0          2m
  nebula-storaged-2   1/1     Running   0          2m
  nebula-storaged-3   1/1     Running   0          5m
  nebula-storaged-4   1/1     Running   0          5m
  ```
  由上可看出 Storage 服务的副本数被扩容至 5 个。

### 缩容集群

缩容集群的原理和扩容一样，用户只需将`apps_v1alpha1_nebulacluster.yaml`文件中的`replicas`的值缩小。具体操作，请参考上文的**扩容集群**部分。

!!! caution

    目前仅支持对{{nebula.name}}集群中的 Graph 服务和 Storage 服务进行扩缩容，不支持扩缩容 Meta 服务。

{{ ent.ent_end }}

## 删除集群

使用 Kubectl 删除{{nebula.name}}集群的命令如下：

```bash
kubectl delete -f apps_v1alpha1_nebulacluster.yaml
```

## 后续操作

[连接{{nebula.name}}数据库](../4.connect-to-nebula-graph-service.md)

